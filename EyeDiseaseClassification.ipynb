{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzZomIzikyDP",
        "outputId": "566aa0a3-ec42-4c05-c19f-271d248ddf8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zH9Upttk0cr",
        "outputId": "047e3b2f-60ee-4673-c8b0-63bcb0d3c04e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "bxyi0on8k0Zs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "0qfyfWdEElMq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d gunavenkatdoddi/eye-diseases-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4uLVRimk0Wj",
        "outputId": "a2e959e5-d089-4d14-c910-b085aedd1dba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading eye-diseases-classification.zip to /content\n",
            "100% 733M/736M [00:07<00:00, 140MB/s]\n",
            "100% 736M/736M [00:07<00:00, 99.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders"
      ],
      "metadata": {
        "id": "OisMlKXwk0Tr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a95c5d-50fb-4f0b-d05f-3cdc9cb6f48c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders"
      ],
      "metadata": {
        "id": "ueATSY-Tk0Qc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip file\n",
        "zip_file_path = '/content/eye-diseases-classification.zip'\n",
        "\n",
        "# Directory where you want to extract the contents\n",
        "extracted_dir = '/content/extracted_data'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(extracted_dir, exist_ok=True)\n",
        "\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Extract all the contents into the output directory\n",
        "    zip_ref.extractall(extracted_dir)\n",
        "\n",
        "# Now the contents of the zip file are extracted to the 'extracted_data' directory\n"
      ],
      "metadata": {
        "id": "XaZpdmTpG4DQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitfolders.ratio('/content/extracted_data/dataset', output=\"output\", seed=1337, ratio=(.8, 0.2))"
      ],
      "metadata": {
        "id": "4O4qTsbVk0NL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6207504c-82ea-4d6d-cc06-2c20ab6a2c82"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 4217 files [00:02, 1424.18 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = [224, 224]"
      ],
      "metadata": {
        "id": "1TODiAhok0KD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "from tensorflow.keras.preprocessing. image import ImageDataGenerator\n",
        "from PIL import ImageFile\n",
        "ImageFile. LOAD_TRUNCATED_IMAGES = True\n",
        "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "prdl16rXk0G8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing. image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "shear_range = 0.2, zoom_range = 0.2,\n",
        "horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "QQnJblLrk0EG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory(\n",
        "'/content/output/train',\n",
        "target_size = (224, 224),\n",
        "batch_size = 64,\n",
        "class_mode = 'categorical')\n",
        "test_set = test_datagen. flow_from_directory('/content/output/val',\n",
        "target_size = (224, 224),\n",
        "batch_size = 64,\n",
        "class_mode = 'categorical')"
      ],
      "metadata": {
        "id": "GlbITfQMk0At",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6804226-70fc-4013-9149-cbadfb62240b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3372 images belonging to 4 classes.\n",
            "Found 845 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VGG19 = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet',include_top=False)"
      ],
      "metadata": {
        "id": "80cU642Okz93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f8fb742-b945-4d77-c546-22eb4e79bc41"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in VGG19.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "SiR9EWzFkz6r"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(VGG19.output)"
      ],
      "metadata": {
        "id": "_NgSNIaxkz3k"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(VGG19.output)"
      ],
      "metadata": {
        "id": "hma3llyTkz0r"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = Dense(4, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "Y2tr09s5kzx1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=VGG19.input, outputs=prediction)"
      ],
      "metadata": {
        "id": "itYiRNEykzuU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model. summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I-1B_S9IoJx",
        "outputId": "a77a20e4-8031-4395-9880-10c82b288986"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 100356    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20124740 (76.77 MB)\n",
            "Trainable params: 100356 (392.02 KB)\n",
            "Non-trainable params: 20024384 (76.39 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "cRie_i5kIoEG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.fit(\n",
        "training_set,\n",
        "validation_data=test_set,\n",
        "epochs=2,\n",
        "steps_per_epoch=len(training_set),\n",
        "validation_steps=len(test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTkDY4cgIn-a",
        "outputId": "bc10532a-24ba-49ba-bfb5-bb1b110eeabe"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "53/53 [==============================] - 3311s 63s/step - loss: 0.5524 - accuracy: 0.7841 - val_loss: 0.6099 - val_accuracy: 0.7479\n",
            "Epoch 2/2\n",
            "53/53 [==============================] - 3354s 63s/step - loss: 0.5062 - accuracy: 0.8060 - val_loss: 0.4787 - val_accuracy: 0.8308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('animal.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYuMRgE2In7f",
        "outputId": "1e5db8b5-5ed0-4b7e-ee9e-81b1b8baa28a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "model = load_model(\"/content/animal.h5\")\n"
      ],
      "metadata": {
        "id": "PWx3fWcMIn4t"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = image. load_img(r\"/content/output/val/normal/2365_left.jpg\",target_size= (224,224))#loading of the image\n",
        "x = image.img_to_array(img)#image to array\n",
        "x = np.expand_dims(x,axis = 0)#changing the shape\n",
        "preds=model.predict(x)\n",
        "pred=np.argmax(preds,axis=1)\n",
        "index=['cataract', 'diabetic_retinopathy', 'glaucoma' , 'normal']\n",
        "result=str(index[pred[0]])\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "q_pflamdIn1f",
        "outputId": "e4d897ad-186e-4da1-9934-8b7de6f18979"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'normal'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "He1Sx1jZxfri"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}